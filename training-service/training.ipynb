{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ./data\n",
    "! mkdir ./data\n",
    "! tar -xf ./file.tgz -C ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 2 classes.\n",
      "Using 2400 files for training.\n",
      "Using 600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (img_height, img_width)\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    \"./data\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,img_width,3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 647ms/step - accuracy: 0.5061 - loss: 1.1676 - val_accuracy: 0.5083 - val_loss: 0.6911\n",
      "Epoch 2/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 574ms/step - accuracy: 0.5313 - loss: 0.6879 - val_accuracy: 0.5817 - val_loss: 0.6757\n",
      "Epoch 3/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.6113 - loss: 0.6620 - val_accuracy: 0.6233 - val_loss: 0.6477\n",
      "Epoch 4/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 511ms/step - accuracy: 0.6638 - loss: 0.6201 - val_accuracy: 0.6400 - val_loss: 0.6447\n",
      "Epoch 5/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 505ms/step - accuracy: 0.6929 - loss: 0.5914 - val_accuracy: 0.6750 - val_loss: 0.6063\n",
      "Epoch 6/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 519ms/step - accuracy: 0.7033 - loss: 0.5793 - val_accuracy: 0.6533 - val_loss: 0.6456\n",
      "Epoch 7/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 543ms/step - accuracy: 0.7082 - loss: 0.5795 - val_accuracy: 0.6500 - val_loss: 0.6484\n",
      "Epoch 8/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 513ms/step - accuracy: 0.6985 - loss: 0.5692 - val_accuracy: 0.6717 - val_loss: 0.6219\n",
      "Epoch 9/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 515ms/step - accuracy: 0.7467 - loss: 0.5300 - val_accuracy: 0.7200 - val_loss: 0.5702\n",
      "Epoch 10/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 538ms/step - accuracy: 0.7104 - loss: 0.5627 - val_accuracy: 0.7217 - val_loss: 0.5824\n",
      "Epoch 11/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 588ms/step - accuracy: 0.7385 - loss: 0.5357 - val_accuracy: 0.7133 - val_loss: 0.5930\n",
      "Epoch 12/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 567ms/step - accuracy: 0.7227 - loss: 0.5386 - val_accuracy: 0.7150 - val_loss: 0.5679\n",
      "Epoch 13/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 580ms/step - accuracy: 0.7428 - loss: 0.5218 - val_accuracy: 0.7383 - val_loss: 0.5386\n",
      "Epoch 14/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 536ms/step - accuracy: 0.7659 - loss: 0.4964 - val_accuracy: 0.6933 - val_loss: 0.5900\n",
      "Epoch 15/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 491ms/step - accuracy: 0.7574 - loss: 0.5079 - val_accuracy: 0.7317 - val_loss: 0.5608\n",
      "Epoch 16/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 520ms/step - accuracy: 0.7885 - loss: 0.4740 - val_accuracy: 0.7483 - val_loss: 0.5154\n",
      "Epoch 17/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 485ms/step - accuracy: 0.7782 - loss: 0.4828 - val_accuracy: 0.7267 - val_loss: 0.5647\n",
      "Epoch 18/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 575ms/step - accuracy: 0.7717 - loss: 0.4891 - val_accuracy: 0.7550 - val_loss: 0.5105\n",
      "Epoch 19/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 557ms/step - accuracy: 0.7809 - loss: 0.4660 - val_accuracy: 0.7267 - val_loss: 0.5381\n",
      "Epoch 20/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 566ms/step - accuracy: 0.7823 - loss: 0.4790 - val_accuracy: 0.7567 - val_loss: 0.4979\n",
      "Epoch 21/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 579ms/step - accuracy: 0.7940 - loss: 0.4495 - val_accuracy: 0.7317 - val_loss: 0.5434\n",
      "Epoch 22/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 568ms/step - accuracy: 0.7788 - loss: 0.4728 - val_accuracy: 0.7633 - val_loss: 0.4983\n",
      "Epoch 23/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 588ms/step - accuracy: 0.7894 - loss: 0.4440 - val_accuracy: 0.7350 - val_loss: 0.5350\n",
      "Epoch 24/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 533ms/step - accuracy: 0.7832 - loss: 0.4671 - val_accuracy: 0.7367 - val_loss: 0.5506\n",
      "Epoch 25/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 501ms/step - accuracy: 0.7934 - loss: 0.4405 - val_accuracy: 0.7700 - val_loss: 0.5110\n",
      "Epoch 26/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 498ms/step - accuracy: 0.8047 - loss: 0.4158 - val_accuracy: 0.7583 - val_loss: 0.5226\n",
      "Epoch 27/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 528ms/step - accuracy: 0.7780 - loss: 0.4571 - val_accuracy: 0.7600 - val_loss: 0.5244\n",
      "Epoch 28/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 525ms/step - accuracy: 0.8189 - loss: 0.4161 - val_accuracy: 0.7733 - val_loss: 0.4850\n",
      "Epoch 29/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 516ms/step - accuracy: 0.8227 - loss: 0.4116 - val_accuracy: 0.7400 - val_loss: 0.5433\n",
      "Epoch 30/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 539ms/step - accuracy: 0.8030 - loss: 0.4304 - val_accuracy: 0.7733 - val_loss: 0.4950\n",
      "Epoch 31/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 566ms/step - accuracy: 0.8163 - loss: 0.4377 - val_accuracy: 0.7350 - val_loss: 0.5458\n",
      "Epoch 32/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 541ms/step - accuracy: 0.7863 - loss: 0.4480 - val_accuracy: 0.7550 - val_loss: 0.5423\n",
      "Epoch 33/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 605ms/step - accuracy: 0.8039 - loss: 0.4076 - val_accuracy: 0.7717 - val_loss: 0.5170\n",
      "Epoch 34/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 611ms/step - accuracy: 0.8284 - loss: 0.3884 - val_accuracy: 0.7783 - val_loss: 0.5252\n",
      "Epoch 35/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 525ms/step - accuracy: 0.8249 - loss: 0.3878 - val_accuracy: 0.7767 - val_loss: 0.5002\n",
      "Epoch 36/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 543ms/step - accuracy: 0.8265 - loss: 0.4040 - val_accuracy: 0.7650 - val_loss: 0.5226\n",
      "Epoch 37/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 516ms/step - accuracy: 0.8082 - loss: 0.3967 - val_accuracy: 0.7450 - val_loss: 0.5549\n",
      "Epoch 38/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.8174 - loss: 0.3962 - val_accuracy: 0.7617 - val_loss: 0.5417\n",
      "Epoch 39/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 510ms/step - accuracy: 0.8230 - loss: 0.3936 - val_accuracy: 0.7733 - val_loss: 0.5157\n",
      "Epoch 40/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 537ms/step - accuracy: 0.8405 - loss: 0.3650 - val_accuracy: 0.7917 - val_loss: 0.5191\n",
      "Epoch 41/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 578ms/step - accuracy: 0.8285 - loss: 0.3829 - val_accuracy: 0.7717 - val_loss: 0.5593\n",
      "Epoch 42/50\n",
      "\u001b[1m 5/19\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 464ms/step - accuracy: 0.8419 - loss: 0.3777"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "This image most likely belongs to dogs with a 65.71 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "data_url = \"file://\" + os.path.expanduser(\"~/Downloads/test_cat2.jpg\")\n",
    "data_path = tf.keras.utils.get_file('test_cat2', origin=data_url)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    data_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
